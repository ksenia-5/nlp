{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2c1cac0",
   "metadata": {
    "papermill": {
     "duration": 0.00795,
     "end_time": "2022-12-04T17:08:13.625884",
     "exception": false,
     "start_time": "2022-12-04T17:08:13.617934",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Chatbot\n",
    "\n",
    "Build a **corpus-based conversational chatbot using NLTK and python**, using this [reference tutorial](https://medium.com/swlh/a-chatbot-in-python-using-nltk-938a37a9eacc) for guidance and ideas.\n",
    "<br><br>\n",
    "\n",
    "Perform the following tasks:\n",
    "1. Use the dataset provided in the tutorial, or develop your own dataset with similar structure.\n",
    "2. Perform text normalisation: convert text to lowercase,remove special characters, and perform lemmatisation; remove any stopwords.\n",
    "3. Use word embeddings such as:bag of words and TF-IDF, and compute cosine similarity.\n",
    "4. Compare the performance and results of the two methods,i.e. bag of words (BOW) and TF-IDF.\n",
    "5. Customise using any of the NLP techniques we have learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f066428",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-12-04T17:08:13.641556Z",
     "iopub.status.busy": "2022-12-04T17:08:13.640886Z",
     "iopub.status.idle": "2022-12-04T17:08:16.528016Z",
     "shell.execute_reply": "2022-12-04T17:08:16.526362Z"
    },
    "papermill": {
     "duration": 2.897889,
     "end_time": "2022-12-04T17:08:16.530879",
     "exception": false,
     "start_time": "2022-12-04T17:08:13.632990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/dataset/dialog_talk_agent.xlsx\n"
     ]
    }
   ],
   "source": [
    "import nltk, re # NLTK library of language resources\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Part of speech tagging and tokenisation\n",
    "from nltk import pos_tag, word_tokenize \n",
    "\n",
    "# to perform lemmatisation\n",
    "from nltk.stem import wordnet \n",
    "\n",
    "# stopwords\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# to perform bow and tfidf\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# For cosine similarity\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "# Data processing and visualisation\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Image\n",
    "\n",
    "# Pandas and print rounding\n",
    "pd.set_option('precision', 3) \n",
    "%precision 3\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75e3701",
   "metadata": {
    "papermill": {
     "duration": 0.005777,
     "end_time": "2022-12-04T17:08:16.542736",
     "exception": false,
     "start_time": "2022-12-04T17:08:16.536959",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Import the dataset (corpus) into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b1d06fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T17:08:16.557260Z",
     "iopub.status.busy": "2022-12-04T17:08:16.556821Z",
     "iopub.status.idle": "2022-12-04T17:08:17.146956Z",
     "shell.execute_reply": "2022-12-04T17:08:17.145549Z"
    },
    "papermill": {
     "duration": 0.601652,
     "end_time": "2022-12-04T17:08:17.150833",
     "exception": false,
     "start_time": "2022-12-04T17:08:16.549181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Text Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tell me about your personality</td>\n",
       "      <td>Just think of me as the ace up your sleeve.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I want to know you better</td>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Define yourself</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Describe yourself</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tell me about yourself</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>all about you</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tell me some stuff about you</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>talk some stuff about you</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>talk about yourself</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>about yourself</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>who are you</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>introduce yourself</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I want to know more about you</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>what are you</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>what is your personality</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Context  \\\n",
       "0   Tell me about your personality   \n",
       "1        I want to know you better   \n",
       "2                  Define yourself   \n",
       "3                Describe yourself   \n",
       "4           tell me about yourself   \n",
       "5                    all about you   \n",
       "6     tell me some stuff about you   \n",
       "7        talk some stuff about you   \n",
       "8              talk about yourself   \n",
       "9                   about yourself   \n",
       "10                     who are you   \n",
       "11              introduce yourself   \n",
       "12   I want to know more about you   \n",
       "13                    what are you   \n",
       "14        what is your personality   \n",
       "\n",
       "                                    Text Response  \n",
       "0     Just think of me as the ace up your sleeve.  \n",
       "1   I can help you work smarter instead of harder  \n",
       "2                                             NaN  \n",
       "3                                             NaN  \n",
       "4                                             NaN  \n",
       "5                                             NaN  \n",
       "6                                             NaN  \n",
       "7                                             NaN  \n",
       "8                                             NaN  \n",
       "9                                             NaN  \n",
       "10                                            NaN  \n",
       "11                                            NaN  \n",
       "12                                            NaN  \n",
       "13                                            NaN  \n",
       "14                                            NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"../input/dataset/dialog_talk_agent.xlsx\")\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2699aa4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T17:08:17.167387Z",
     "iopub.status.busy": "2022-12-04T17:08:17.166984Z",
     "iopub.status.idle": "2022-12-04T17:08:17.175861Z",
     "shell.execute_reply": "2022-12-04T17:08:17.173753Z"
    },
    "papermill": {
     "duration": 0.020983,
     "end_time": "2022-12-04T17:08:17.179161",
     "exception": false,
     "start_time": "2022-12-04T17:08:17.158178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1592, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8e153d",
   "metadata": {
    "papermill": {
     "duration": 0.006075,
     "end_time": "2022-12-04T17:08:17.193346",
     "exception": false,
     "start_time": "2022-12-04T17:08:17.187271",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There are 1592 entries in the dataset, each entry giving a turn-response in the conversation, similar questions are grouped together and NaN values indicate a response similar to the previous entry.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "944595e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T17:08:17.209869Z",
     "iopub.status.busy": "2022-12-04T17:08:17.208812Z",
     "iopub.status.idle": "2022-12-04T17:08:17.228514Z",
     "shell.execute_reply": "2022-12-04T17:08:17.226660Z"
    },
    "papermill": {
     "duration": 0.031388,
     "end_time": "2022-12-04T17:08:17.231354",
     "exception": false,
     "start_time": "2022-12-04T17:08:17.199966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Text Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tell me about your personality</td>\n",
       "      <td>Just think of me as the ace up your sleeve.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I want to know you better</td>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Define yourself</td>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Describe yourself</td>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tell me about yourself</td>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>all about you</td>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tell me some stuff about you</td>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>talk some stuff about you</td>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>talk about yourself</td>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>about yourself</td>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Context  \\\n",
       "0  Tell me about your personality   \n",
       "1       I want to know you better   \n",
       "2                 Define yourself   \n",
       "3               Describe yourself   \n",
       "4          tell me about yourself   \n",
       "5                   all about you   \n",
       "6    tell me some stuff about you   \n",
       "7       talk some stuff about you   \n",
       "8             talk about yourself   \n",
       "9                  about yourself   \n",
       "\n",
       "                                   Text Response  \n",
       "0    Just think of me as the ace up your sleeve.  \n",
       "1  I can help you work smarter instead of harder  \n",
       "2  I can help you work smarter instead of harder  \n",
       "3  I can help you work smarter instead of harder  \n",
       "4  I can help you work smarter instead of harder  \n",
       "5  I can help you work smarter instead of harder  \n",
       "6  I can help you work smarter instead of harder  \n",
       "7  I can help you work smarter instead of harder  \n",
       "8  I can help you work smarter instead of harder  \n",
       "9  I can help you work smarter instead of harder  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace null values with previous value\n",
    "df.ffill(axis = 0, inplace = True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e580a7",
   "metadata": {
    "papermill": {
     "duration": 0.007171,
     "end_time": "2022-12-04T17:08:17.245167",
     "exception": false,
     "start_time": "2022-12-04T17:08:17.237996",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Text normalisation (lower case, remove special characters, lemmatisation)\n",
    "* word embedding (bag of words (BOW), TF-IDF)\n",
    "* cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6ea2c56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T17:08:17.263147Z",
     "iopub.status.busy": "2022-12-04T17:08:17.262297Z",
     "iopub.status.idle": "2022-12-04T17:08:17.267911Z",
     "shell.execute_reply": "2022-12-04T17:08:17.266629Z"
    },
    "papermill": {
     "duration": 0.017053,
     "end_time": "2022-12-04T17:08:17.270861",
     "exception": false,
     "start_time": "2022-12-04T17:08:17.253808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1 = df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1f6948a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T17:08:17.287147Z",
     "iopub.status.busy": "2022-12-04T17:08:17.285867Z",
     "iopub.status.idle": "2022-12-04T17:08:17.298847Z",
     "shell.execute_reply": "2022-12-04T17:08:17.297023Z"
    },
    "papermill": {
     "duration": 0.02438,
     "end_time": "2022-12-04T17:08:17.301727",
     "exception": false,
     "start_time": "2022-12-04T17:08:17.277347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalise_text(text):\n",
    "    '''\n",
    "    Function takes a text string (utterance) as input, \n",
    "    converts to lowercase, \n",
    "    removes special characters and punctuation, \n",
    "    tokenises, POS-tags and lemmatises each token..\n",
    "    Joins lemmatised tokens, and returns lemmatised string.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # convert to lowercase\n",
    "    text = str(text).lower()\n",
    "        \n",
    "    # remove special characters\n",
    "    text = re.sub(r'[^a-z0-9]', \" \",text)\n",
    "        \n",
    "    # tokenise\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Initialise lemmatiser\n",
    "    lemmatiser = wordnet.WordNetLemmatizer()\n",
    "    \n",
    "    # Part of speech (POS) tagging, tagset set to default\n",
    "    tagged_tokens =  pos_tag(tokens, tagset = None)\n",
    "\n",
    "    # Empty list\n",
    "    token_lemmas = []\n",
    "    for (token, pos_token) in tagged_tokens:\n",
    "        if pos_token.startswith(\"V\"): # verb\n",
    "            pos_val = \"v\"\n",
    "        elif pos_token.startswith(\"J\"): # adjective\n",
    "            pos_val = \"a\"\n",
    "        elif pos_token.startswith(\"R\"): # adverb\n",
    "            pos_val = \"r\"\n",
    "        else:\n",
    "            pos_val = 'n' # noun\n",
    "        \n",
    "        # lemmatise and append to list of lemmatised tokens\n",
    "        token_lemmas.append(lemmatiser.lemmatize(token, pos_val))\n",
    "    \n",
    "    return \" \".join(token_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b489ace",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T17:08:17.317728Z",
     "iopub.status.busy": "2022-12-04T17:08:17.317269Z",
     "iopub.status.idle": "2022-12-04T17:08:19.525450Z",
     "shell.execute_reply": "2022-12-04T17:08:19.524096Z"
    },
    "papermill": {
     "duration": 2.219867,
     "end_time": "2022-12-04T17:08:19.528204",
     "exception": false,
     "start_time": "2022-12-04T17:08:17.308337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you be overanalysing thing why do we need lemmatisation'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalise_text(\"Oh my days!\")\n",
    "normalise_text(\"Can't wait to get Korean again!!\")\n",
    "normalise_text(\"You are overanalysing things! Why do we need lemmatisation?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "246ed388",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T17:08:19.543685Z",
     "iopub.status.busy": "2022-12-04T17:08:19.543278Z",
     "iopub.status.idle": "2022-12-04T17:08:20.373920Z",
     "shell.execute_reply": "2022-12-04T17:08:20.372866Z"
    },
    "papermill": {
     "duration": 0.84182,
     "end_time": "2022-12-04T17:08:20.376531",
     "exception": false,
     "start_time": "2022-12-04T17:08:19.534711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Text Response</th>\n",
       "      <th>lemmatised_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tell me about your personality</td>\n",
       "      <td>Just think of me as the ace up your sleeve.</td>\n",
       "      <td>tell me about your personality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I want to know you better</td>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "      <td>i want to know you good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Define yourself</td>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "      <td>define yourself</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Describe yourself</td>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "      <td>describe yourself</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tell me about yourself</td>\n",
       "      <td>I can help you work smarter instead of harder</td>\n",
       "      <td>tell me about yourself</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Context  \\\n",
       "0  Tell me about your personality   \n",
       "1       I want to know you better   \n",
       "2                 Define yourself   \n",
       "3               Describe yourself   \n",
       "4          tell me about yourself   \n",
       "\n",
       "                                   Text Response  \\\n",
       "0    Just think of me as the ace up your sleeve.   \n",
       "1  I can help you work smarter instead of harder   \n",
       "2  I can help you work smarter instead of harder   \n",
       "3  I can help you work smarter instead of harder   \n",
       "4  I can help you work smarter instead of harder   \n",
       "\n",
       "                  lemmatised_text  \n",
       "0  tell me about your personality  \n",
       "1         i want to know you good  \n",
       "2                 define yourself  \n",
       "3               describe yourself  \n",
       "4          tell me about yourself  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply the normalise_text function to each entry in the context column\n",
    "df[\"lemmatised_text\"] = df[\"Context\"].apply(normalise_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d2415c",
   "metadata": {
    "papermill": {
     "duration": 0.006236,
     "end_time": "2022-12-04T17:08:20.389545",
     "exception": false,
     "start_time": "2022-12-04T17:08:20.383309",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "926cd07d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T17:08:20.404990Z",
     "iopub.status.busy": "2022-12-04T17:08:20.404494Z",
     "iopub.status.idle": "2022-12-04T17:08:20.411155Z",
     "shell.execute_reply": "2022-12-04T17:08:20.409823Z"
    },
    "papermill": {
     "duration": 0.017384,
     "end_time": "2022-12-04T17:08:20.413658",
     "exception": false,
     "start_time": "2022-12-04T17:08:20.396274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    \n",
    "    # stopwords\n",
    "    stop = stopwords.words(\"english\")\n",
    "    \n",
    "    #if token not in stop\n",
    "    text = [word for word in text.split() if word not in stop]\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd203ae",
   "metadata": {
    "papermill": {
     "duration": 0.006421,
     "end_time": "2022-12-04T17:08:20.426906",
     "exception": false,
     "start_time": "2022-12-04T17:08:20.420485",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Bag of words (BOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2544c990",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T17:08:20.442238Z",
     "iopub.status.busy": "2022-12-04T17:08:20.441518Z",
     "iopub.status.idle": "2022-12-04T17:08:20.485530Z",
     "shell.execute_reply": "2022-12-04T17:08:20.484230Z"
    },
    "papermill": {
     "duration": 0.05505,
     "end_time": "2022-12-04T17:08:20.488556",
     "exception": false,
     "start_time": "2022-12-04T17:08:20.433506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>21</th>\n",
       "      <th>abort</th>\n",
       "      <th>about</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>abysmal</th>\n",
       "      <th>actually</th>\n",
       "      <th>adore</th>\n",
       "      <th>advice</th>\n",
       "      <th>advise</th>\n",
       "      <th>affirmative</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>yeh</th>\n",
       "      <th>yep</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>yours</th>\n",
       "      <th>yourself</th>\n",
       "      <th>yup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 491 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   21  abort  about  absolutely  abysmal  actually  adore  advice  advise  \\\n",
       "0   0      0      1           0        0         0      0       0       0   \n",
       "1   0      0      0           0        0         0      0       0       0   \n",
       "2   0      0      0           0        0         0      0       0       0   \n",
       "3   0      0      0           0        0         0      0       0       0   \n",
       "4   0      0      1           0        0         0      0       0       0   \n",
       "\n",
       "   affirmative  ...  year  yeh  yep  yes  yet  you  your  yours  yourself  yup  \n",
       "0            0  ...     0    0    0    0    0    0     1      0         0    0  \n",
       "1            0  ...     0    0    0    0    0    1     0      0         0    0  \n",
       "2            0  ...     0    0    0    0    0    0     0      0         1    0  \n",
       "3            0  ...     0    0    0    0    0    0     0      0         1    0  \n",
       "4            0  ...     0    0    0    0    0    0     0      0         1    0  \n",
       "\n",
       "[5 rows x 491 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count vectoriser \n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(df[\"lemmatised_text\"]).toarray()\n",
    "\n",
    "features = cv.get_feature_names_out()\n",
    "df_bow = pd.DataFrame(X, columns = features)\n",
    "df_bow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1355d060",
   "metadata": {
    "papermill": {
     "duration": 0.007177,
     "end_time": "2022-12-04T17:08:20.504653",
     "exception": false,
     "start_time": "2022-12-04T17:08:20.497476",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utterance\n",
    "s = string input to the chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b80a8b92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T17:08:20.522291Z",
     "iopub.status.busy": "2022-12-04T17:08:20.521882Z",
     "iopub.status.idle": "2022-12-04T17:08:20.562510Z",
     "shell.execute_reply": "2022-12-04T17:08:20.560799Z"
    },
    "papermill": {
     "duration": 0.052426,
     "end_time": "2022-12-04T17:08:20.565644",
     "exception": false,
     "start_time": "2022-12-04T17:08:20.513218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help me!\n",
      "help me\n"
     ]
    }
   ],
   "source": [
    "# Utterance preprocessing - remove stopwords and normalise text\n",
    "\n",
    "#s = \"I can't believe how tasty the Korean is!!! We should go there again!\"\n",
    "#s = \"What's the weather like tomorrow?\"\n",
    "s = \"Help me!\"\n",
    "\n",
    "t = remove_stopwords(s)\n",
    "print(t)\n",
    "\n",
    "u = normalise_text(t)\n",
    "print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78fc7eac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T17:08:20.582599Z",
     "iopub.status.busy": "2022-12-04T17:08:20.581404Z",
     "iopub.status.idle": "2022-12-04T17:08:20.615004Z",
     "shell.execute_reply": "2022-12-04T17:08:20.613731Z"
    },
    "papermill": {
     "duration": 0.046619,
     "end_time": "2022-12-04T17:08:20.619429",
     "exception": false,
     "start_time": "2022-12-04T17:08:20.572810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help me!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm glad to help. What can I do for you?\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the preprocessed utterance to bag of words\n",
    "u_bow = cv.transform([u]).toarray()\n",
    "\n",
    "# Apply the cosine similarity to utternace to search for \n",
    "# most similar utterance in training dataset bow\n",
    "cosine_value = 1 - pairwise_distances(df_bow, u_bow, metric = \"cosine\")\n",
    "\n",
    "# cosine_value calculates similarity between utterance and each entry in the dataset\n",
    "\n",
    "# print the question\n",
    "print(s)\n",
    "\n",
    "# Get the index of the most similar entry\n",
    "index_value1 = cosine_value.argmax()\n",
    "\n",
    "# Get the response of the most similar entry \n",
    "df.loc[index_value1,\"Text Response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4184f036",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T17:08:20.660484Z",
     "iopub.status.busy": "2022-12-04T17:08:20.659658Z",
     "iopub.status.idle": "2022-12-04T17:08:20.749125Z",
     "shell.execute_reply": "2022-12-04T17:08:20.747872Z"
    },
    "papermill": {
     "duration": 0.113441,
     "end_time": "2022-12-04T17:08:20.752156",
     "exception": false,
     "start_time": "2022-12-04T17:08:20.638715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>21</th>\n",
       "      <th>abort</th>\n",
       "      <th>about</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>abysmal</th>\n",
       "      <th>actually</th>\n",
       "      <th>adore</th>\n",
       "      <th>advice</th>\n",
       "      <th>advise</th>\n",
       "      <th>affirmative</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>yeh</th>\n",
       "      <th>yep</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>yours</th>\n",
       "      <th>yourself</th>\n",
       "      <th>yup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 491 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    21  abort  about  absolutely  abysmal  actually  adore  advice  advise  \\\n",
       "0  0.0    0.0  0.408         0.0      0.0       0.0    0.0     0.0     0.0   \n",
       "1  0.0    0.0  0.000         0.0      0.0       0.0    0.0     0.0     0.0   \n",
       "2  0.0    0.0  0.000         0.0      0.0       0.0    0.0     0.0     0.0   \n",
       "3  0.0    0.0  0.000         0.0      0.0       0.0    0.0     0.0     0.0   \n",
       "4  0.0    0.0  0.454         0.0      0.0       0.0    0.0     0.0     0.0   \n",
       "\n",
       "   affirmative  ...  year  yeh  yep  yes  yet    you   your  yours  yourself  \\\n",
       "0          0.0  ...   0.0  0.0  0.0  0.0  0.0  0.000  0.331    0.0     0.000   \n",
       "1          0.0  ...   0.0  0.0  0.0  0.0  0.0  0.205  0.000    0.0     0.000   \n",
       "2          0.0  ...   0.0  0.0  0.0  0.0  0.0  0.000  0.000    0.0     0.642   \n",
       "3          0.0  ...   0.0  0.0  0.0  0.0  0.0  0.000  0.000    0.0     0.642   \n",
       "4          0.0  ...   0.0  0.0  0.0  0.0  0.0  0.000  0.000    0.0     0.609   \n",
       "\n",
       "   yup  \n",
       "0  0.0  \n",
       "1  0.0  \n",
       "2  0.0  \n",
       "3  0.0  \n",
       "4  0.0  \n",
       "\n",
       "[5 rows x 491 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialise sklearn tfidf\n",
    "tfidf = TfidfVectorizer()\n",
    "x_tfidf = tfidf.fit_transform(df[\"lemmatised_text\"]).toarray()\n",
    "df_tfidf = pd.DataFrame(x_tfidf, columns = tfidf.get_feature_names_out())\n",
    "df_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1100b179",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T17:08:20.773053Z",
     "iopub.status.busy": "2022-12-04T17:08:20.772303Z",
     "iopub.status.idle": "2022-12-04T17:08:20.800794Z",
     "shell.execute_reply": "2022-12-04T17:08:20.799355Z"
    },
    "papermill": {
     "duration": 0.044,
     "end_time": "2022-12-04T17:08:20.805547",
     "exception": false,
     "start_time": "2022-12-04T17:08:20.761547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do you like mango\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Thanks! The feeling is mutual.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"Want to come for dinner?\"\n",
    "s = \"How are you doing today?\"\n",
    "s = \"Do you like mangoes?\"\n",
    "\n",
    "def chat_tfidf(text):\n",
    "    \n",
    "    # Lemmatised utterance\n",
    "    text = normalise_text(text)\n",
    "    print(text)\n",
    "    \n",
    "    text_tfidf = tfidf.transform([text]).toarray()\n",
    "    cos = 1 - pairwise_distances(df_tfidf, text_tfidf, metric = \"cosine\")\n",
    "    index_value = cos.argmax()\n",
    "    return df[\"Text Response\"].loc[index_value]\n",
    "\n",
    "chat_tfidf(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621182b1",
   "metadata": {
    "papermill": {
     "duration": 0.021863,
     "end_time": "2022-12-04T17:08:20.848821",
     "exception": false,
     "start_time": "2022-12-04T17:08:20.826958",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## MODIFICATIONS\n",
    "* Extend the training corpus - use NLTK chat corpus for BOW\n",
    "* Hybrid - introduce rules to integrate rules based conversation\n",
    "* Adapt BERT or GPT-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04dff7c",
   "metadata": {
    "papermill": {
     "duration": 0.02082,
     "end_time": "2022-12-04T17:08:20.891420",
     "exception": false,
     "start_time": "2022-12-04T17:08:20.870600",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## REFERENCES\n",
    "\n",
    "* [Chatbot tutorial by Bhargava Sai Reddy P](https://medium.com/swlh/a-chatbot-in-python-using-nltk-938a37a9eacc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19.869182,
   "end_time": "2022-12-04T17:08:22.340871",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-12-04T17:08:02.471689",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
